{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bluecast处理完数据后，加载模型训练的功能学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "处理完数据后，对数据drop掉一些，设置模型的参数，自定义myCustomPrepocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "train=pd.read_csv('train.csv')\n",
    "test=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"NObeyesdad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20758 entries, 0 to 20757\n",
      "Data columns (total 18 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   id                              20758 non-null  int64  \n",
      " 1   Gender                          20758 non-null  object \n",
      " 2   Age                             20758 non-null  float64\n",
      " 3   Height                          20758 non-null  float64\n",
      " 4   Weight                          20758 non-null  float64\n",
      " 5   family_history_with_overweight  20758 non-null  object \n",
      " 6   FAVC                            20758 non-null  object \n",
      " 7   FCVC                            20758 non-null  float64\n",
      " 8   NCP                             20758 non-null  float64\n",
      " 9   CAEC                            20758 non-null  object \n",
      " 10  SMOKE                           20758 non-null  object \n",
      " 11  CH2O                            20758 non-null  float64\n",
      " 12  SCC                             20758 non-null  object \n",
      " 13  FAF                             20758 non-null  float64\n",
      " 14  TUE                             20758 non-null  float64\n",
      " 15  CALC                            20758 non-null  object \n",
      " 16  MTRANS                          20758 non-null  object \n",
      " 17  NObeyesdad                      20758 non-null  object \n",
      "dtypes: float64(8), int64(1), object(9)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def transform_feats(data):\n",
    "    data['Gender_binary'] = data['Gender'].map({'Male': 1, 'Female': 0}).astype(int)\n",
    "    data['family_history_with_overweight_binary'] = data['family_history_with_overweight'].map({'yes': 1, 'no': 0}).astype(int)\n",
    "    data['SMOKE_binary'] = data['SMOKE'].map({'yes': 1, 'no': 0}).astype(int)\n",
    "    \n",
    "    # taken from: https://www.kaggle.com/code/ravi20076/playgrounds4e02-extraftre-models\n",
    "    data[\"CAEC\"] = data[\"CAEC\"].map({\"no\": 0, \"Sometimes\": 1, \"Frequently\": 2, \"Always\": 3}).astype(np.uint8)\n",
    "    data['SCC']  = np.where(data[\"SCC\"] == \"no\", 1,0).astype(np.uint8)\n",
    "    data[\"CALC\"] = data[\"CALC\"].map({\"no\": 0, \"Sometimes\": 1, \"Frequently\": 2, \"Always\": 2}).astype(np.uint8)\n",
    "    return data\n",
    "\n",
    "def feature_engineering(data):\n",
    "    # BMI\n",
    "    data['BMI'] = data['Weight'] / (data['Height'] ** 2)\n",
    "    # Activity\n",
    "    data['Activity'] = data['FAF'] * data['TUE']\n",
    "    # Age group\n",
    "    data['Age_Group'] = pd.cut(data['Age'], bins=[0, 18, 30, 45, float('inf')], labels=[0, 1, 2, 3])\n",
    "    data['Age_Group'] = data['Age_Group'].astype(int)\n",
    "    # Height group\n",
    "    data['Height_Group'] = pd.cut(data['Height'], bins=[0, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0, float('inf')], labels=[0, 1, 2, 3, 4, 5, 6])\n",
    "    data['Height_Group'] = data['Height_Group'].astype(int)\n",
    "    #Risk score\n",
    "    data['Risk factor'] = (data['BMI'] + data['Age_Group']) * (data[\"family_history_with_overweight_binary\"] + data[\"SMOKE_binary\"])\n",
    "    \n",
    "    # taken from: https://www.kaggle.com/code/ravi20076/playgrounds4e02-extraftre-models\n",
    "    data[\"BMIbyNCP\"] = np.log1p(data[\"BMI\"]) - np.log1p(data[\"NCP\"])\n",
    "    data[\"BMIFAF\"] = (data[\"BMI\"] * data[\"FAF\"])/ 25.0\n",
    "    data[\"FAFmTUE\"] = data[\"FAF\"] - data[\"TUE\"]\n",
    "    data[\"FCVCpNCP\"] = data['FCVC'] * data['NCP']\n",
    "    data['TechUse'] = np.log1p(data['TUE']) - np.log1p(data['Age'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=transform_feats(train)\n",
    "test=transform_feats(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20758 entries, 0 to 20757\n",
      "Data columns (total 21 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   id                                     20758 non-null  int64  \n",
      " 1   Gender                                 20758 non-null  object \n",
      " 2   Age                                    20758 non-null  float64\n",
      " 3   Height                                 20758 non-null  float64\n",
      " 4   Weight                                 20758 non-null  float64\n",
      " 5   family_history_with_overweight         20758 non-null  object \n",
      " 6   FAVC                                   20758 non-null  object \n",
      " 7   FCVC                                   20758 non-null  float64\n",
      " 8   NCP                                    20758 non-null  float64\n",
      " 9   CAEC                                   20758 non-null  uint8  \n",
      " 10  SMOKE                                  20758 non-null  object \n",
      " 11  CH2O                                   20758 non-null  float64\n",
      " 12  SCC                                    20758 non-null  uint8  \n",
      " 13  FAF                                    20758 non-null  float64\n",
      " 14  TUE                                    20758 non-null  float64\n",
      " 15  CALC                                   20758 non-null  uint8  \n",
      " 16  MTRANS                                 20758 non-null  object \n",
      " 17  NObeyesdad                             20758 non-null  object \n",
      " 18  Gender_binary                          20758 non-null  int32  \n",
      " 19  family_history_with_overweight_binary  20758 non-null  int32  \n",
      " 20  SMOKE_binary                           20758 non-null  int32  \n",
      "dtypes: float64(8), int32(3), int64(1), object(6), uint8(3)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#示例数据\n",
    "data = {\n",
    "    'StudentID': [1, 2, 3, 4, 5, 6],\n",
    "    'Class': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
    "    'Subject': ['Math', 'Math', 'English', 'English', 'Science', 'Science'],\n",
    "    'Score': [85, 90, 75, 80, 95, 85]\n",
    "}\n",
    "\n",
    "#创建DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "现在，我们想要计算每个班级（Class）在每个科目（Subject）上的成绩的均值和标准差，然后计算z-scores。我们调用 get_group_zscores 函数：\n",
    "\n",
    "#使用函数\n",
    "df_with_zscores = get_group_zscores(df, ['Class', 'Subject'], 'Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_zscores(df, group_cols, agg_col):\n",
    "    df_gr = df.groupby(group_cols).agg({agg_col: [\"mean\", \"std\"]}).droplevel(0, axis=1).reset_index()\n",
    "    df_gr[\"mean\"] = df_gr[\"mean\"].fillna(df_gr[\"mean\"].mean())\n",
    "    df_gr[\"std\"] = df_gr[\"std\"].fillna(df_gr[\"std\"].mean())\n",
    "    \n",
    "    identifier = \"_\".join(group_cols) + \"_\" + agg_col\n",
    "    df_gr = df_gr.rename(\n",
    "        columns = {\n",
    "            \"mean\": f\"{identifier}_mean\",\n",
    "            \"std\": f\"{identifier}_std\"\n",
    "        }\n",
    "    )\n",
    "    df = df.merge(df_gr, on=group_cols, how=\"left\")\n",
    "    df[f\"{identifier}_zscore\"] = (df[f\"{identifier}_mean\"] - df[agg_col]) / df[f\"{identifier}_std\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudentID</th>\n",
       "      <th>Class</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Score</th>\n",
       "      <th>Class_Subject_Score_mean</th>\n",
       "      <th>Class_Subject_Score_std</th>\n",
       "      <th>Class_Subject_Score_zscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>Math</td>\n",
       "      <td>85</td>\n",
       "      <td>87.5</td>\n",
       "      <td>3.535534</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>Math</td>\n",
       "      <td>90</td>\n",
       "      <td>87.5</td>\n",
       "      <td>3.535534</td>\n",
       "      <td>-0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "      <td>English</td>\n",
       "      <td>75</td>\n",
       "      <td>77.5</td>\n",
       "      <td>3.535534</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B</td>\n",
       "      <td>English</td>\n",
       "      <td>80</td>\n",
       "      <td>77.5</td>\n",
       "      <td>3.535534</td>\n",
       "      <td>-0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>C</td>\n",
       "      <td>Science</td>\n",
       "      <td>95</td>\n",
       "      <td>90.0</td>\n",
       "      <td>7.071068</td>\n",
       "      <td>-0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>C</td>\n",
       "      <td>Science</td>\n",
       "      <td>85</td>\n",
       "      <td>90.0</td>\n",
       "      <td>7.071068</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   StudentID Class  Subject  Score  Class_Subject_Score_mean  \\\n",
       "0          1     A     Math     85                      87.5   \n",
       "1          2     A     Math     90                      87.5   \n",
       "2          3     B  English     75                      77.5   \n",
       "3          4     B  English     80                      77.5   \n",
       "4          5     C  Science     95                      90.0   \n",
       "5          6     C  Science     85                      90.0   \n",
       "\n",
       "   Class_Subject_Score_std  Class_Subject_Score_zscore  \n",
       "0                 3.535534                    0.707107  \n",
       "1                 3.535534                   -0.707107  \n",
       "2                 3.535534                    0.707107  \n",
       "3                 3.535534                   -0.707107  \n",
       "4                 7.071068                   -0.707107  \n",
       "5                 7.071068                    0.707107  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 示例数据\n",
    "data = {\n",
    "    'StudentID': [1, 2, 3, 4, 5, 6],\n",
    "    'Class': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
    "    'Subject': ['Math', 'Math', 'English', 'English', 'Science', 'Science'],\n",
    "    'Score': [85, 90, 75, 80, 95, 85]\n",
    "}\n",
    "\n",
    "# 创建DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "get_group_zscores(df, ['Class', 'Subject'], 'Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\bluecast\\lib\\site-packages\\pydantic\\_internal\\_fields.py:151: UserWarning: Field \"model_verbosity\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\bluecast\\lib\\site-packages\\pydantic\\_internal\\_fields.py:151: UserWarning: Field \"model_verbosity_during_final_training\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\bluecast\\lib\\site-packages\\pydantic\\_internal\\_fields.py:151: UserWarning: Field \"model_objective\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\bluecast\\lib\\site-packages\\pydantic\\_internal\\_fields.py:151: UserWarning: Field \"model_eval_metric\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\bluecast\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from bluecast.blueprints.cast import BlueCast\n",
    "from bluecast.preprocessing.custom import CustomPreprocessing\n",
    "from typing import Tuple,Optional\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "\n",
    "# add custom last mile computation\n",
    "class CustomInFoldPreprocessing(CustomPreprocessing):\n",
    "    def __init__(self):\n",
    "        self.if_detector = None\n",
    "    # Please note: The base class enforces that the fit_transform method is implemented\n",
    "    def fit_transform(\n",
    "        self, df: pd.DataFrame, target: pd.Series\n",
    "    ) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "        train = df.copy()\n",
    "        train = feature_engineering(train)\n",
    "        train = get_group_zscores(train, [\"Height_Group\", \"Age_Group\"], \"BMI\")\n",
    "        train = get_group_zscores(train, [\"Height_Group\", \"Age_Group\"], \"Risk factor\")\n",
    "        train = get_group_zscores(train, [\"Gender_binary\", \"SMOKE_binary\", \"family_history_with_overweight_binary\"], \"BMI\")\n",
    "        train = get_group_zscores(train, [\"Gender_binary\", \"SMOKE_binary\", \"family_history_with_overweight_binary\"], \"Risk factor\")\n",
    "        train = train.drop([\"source\", \"Age_Group\", \"Height_Group\"], axis=1)\n",
    "        train_target = target.copy().astype(float)\n",
    "        train = train.replace([np.inf, -np.inf], 0)\n",
    "        \n",
    "        # add outlier scores as feature\n",
    "        self.if_detector = IsolationForest(random_state=0)\n",
    "        self.if_detector.fit(train.fillna(0))\n",
    "        train[\"isolation_forest_scores\"] = self.if_detector.predict(train.fillna(0))\n",
    "        return train, train_target\n",
    "\n",
    "    # Please note: The base class enforces that the fit_transform method is implemented\n",
    "    def transform(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        target: Optional[pd.Series] = None,\n",
    "        predicton_mode: bool = False,\n",
    "    ) -> Tuple[pd.DataFrame, Optional[pd.Series]]:\n",
    "        train = df.copy()\n",
    "        \n",
    "        if isinstance(target, pd.Series) or isinstance(target, np.ndarray):\n",
    "            train[\"target\"] = target.copy()\n",
    "            train[\"target\"] = train[\"target\"].astype(float)\n",
    "            train = train.loc[train[\"source\"] == 0].reset_index(drop=True) # no original data\n",
    "            target = train.pop(\"target\")\n",
    "            target = pd.Series(target).astype(float)\n",
    "        \n",
    "        train = feature_engineering(train)\n",
    "        train = get_group_zscores(train, [\"Height_Group\", \"Age_Group\"], \"BMI\")\n",
    "        train = get_group_zscores(train, [\"Height_Group\", \"Age_Group\"], \"Risk factor\")\n",
    "        train = get_group_zscores(train, [\"Gender_binary\", \"SMOKE_binary\", \"family_history_with_overweight_binary\"], \"BMI\")\n",
    "        train = get_group_zscores(train, [\"Gender_binary\", \"SMOKE_binary\", \"family_history_with_overweight_binary\"], \"Risk factor\")\n",
    "        train = train.drop([\"source\", \"Age_Group\", \"Height_Group\"], axis=1)\n",
    "        train = train.replace([np.inf, -np.inf], 0)\n",
    "        \n",
    "        train[\"isolation_forest_scores\"] = self.if_detector.predict(train.fillna(0))\n",
    "        return train, target\n",
    "\n",
    "custom_preprocessor = CustomInFoldPreprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bluecast.config.training_config import TrainingConfig, XgboostTuneParamsConfig\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "# We give more depth\n",
    "xgboost_param_config = XgboostTuneParamsConfig()\n",
    "xgboost_param_config.steps_max = 1000 #epochs数量：过多则浪费计算资源，过拟合风险；过少可能欠拟合\n",
    "xgboost_param_config.max_depth_max = 7 #树的深度：过深有过拟合风险\n",
    "\n",
    "# Create a custom training config and adjust general training parameters\n",
    "train_config = TrainingConfig()\n",
    "train_config.global_random_state = 600 #全局随机状态：保证实验可重复\n",
    "train_config.hypertuning_cv_folds = 1 #交叉验证的分割数量：一般是5，增加计算成本，同时减少过拟合风险\n",
    "train_config.hyperparameter_tuning_rounds = 500 #超参数调优的轮数：500意味着将尝试500种不同的超参数组合\n",
    "train_config.hyperparameter_tuning_max_runtime_secs = 60 * 60 * 2 #最大运行时间为2小时\n",
    "#train_config.enable_grid_search_fine_tuning = True #启用精细调优，模型将在更细致的参数网格上进行搜索\n",
    "train_config.use_full_data_for_final_model = True \n",
    "#使用全部数据训练：最终模型可能会增加过拟合的风险，因为模型可能会过度学习训练数据中的噪声。\n",
    "#如果设置为False，模型可能在一定程度上避免过拟合。\n",
    "#如果最终模型只在部分数据上训练，那么模型的稳定性可能会受到影响，因为它可能没有充分学习到数据的整体分布。\n",
    "train_config.precise_cv_tuning = True #启用精确的交叉验证调优可能意味着在调优过程中会更加精确地评估模型性能。\n",
    "train_config.gridsearch_nb_parameters_per_grid = 5 #在搜索最佳超参数组合时，每个超参数要尝试多少个不同的值。\n",
    "#train_config.cat_encoding_via_ml_algorithm = True \n",
    "#train_config.calculate_shap_values = False\n",
    "\n",
    "skf = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=1987)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bluecast.blueprints.cast_cv import BlueCastCV\n",
    "automl = BlueCastCV(\n",
    "        class_problem=\"multiclass\", # also multiclass is possible\n",
    "        #stratifier=skf,\n",
    "        conf_training=train_config,\n",
    "        conf_xgboost=xgboost_param_config,\n",
    "        custom_in_fold_preprocessor=custom_preprocessor,\n",
    "        #custom_preprocessor=custom_preprocessor,\n",
    "        #ml_model=custom_model_tab,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\bluecast\\lib\\site-packages\\bluecast\\blueprints\\cast_cv.py:169: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train.loc[:, target_col] = y_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting model number 0 with random seed 633\n",
      "2024-03-10 07:13:37.426874: Start checking if GPU is available for usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\bluecast\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [15:13:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "d:\\anaconda3\\envs\\bluecast\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [15:13:37] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\context.cc:44: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "d:\\anaconda3\\envs\\bluecast\\lib\\site-packages\\bluecast\\preprocessing\\feature_types.py:101: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], yearfirst=True)\n",
      "d:\\anaconda3\\envs\\bluecast\\lib\\site-packages\\bluecast\\preprocessing\\feature_types.py:101: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], yearfirst=True)\n",
      "d:\\anaconda3\\envs\\bluecast\\lib\\site-packages\\bluecast\\preprocessing\\feature_types.py:101: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], yearfirst=True)\n",
      "d:\\anaconda3\\envs\\bluecast\\lib\\site-packages\\bluecast\\preprocessing\\feature_types.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = pd.to_datetime(df[col], yearfirst=True)\n",
      "d:\\anaconda3\\envs\\bluecast\\lib\\site-packages\\bluecast\\preprocessing\\feature_types.py:101: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], yearfirst=True)\n",
      "d:\\anaconda3\\envs\\bluecast\\lib\\site-packages\\bluecast\\preprocessing\\feature_types.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = pd.to_datetime(df[col], yearfirst=True)\n",
      "d:\\anaconda3\\envs\\bluecast\\lib\\site-packages\\bluecast\\preprocessing\\feature_types.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = pd.to_datetime(df[col], yearfirst=True)\n",
      "d:\\anaconda3\\envs\\bluecast\\lib\\site-packages\\bluecast\\preprocessing\\feature_types.py:101: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], yearfirst=True)\n",
      "d:\\anaconda3\\envs\\bluecast\\lib\\site-packages\\bluecast\\preprocessing\\feature_types.py:101: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], yearfirst=True)\n",
      "d:\\anaconda3\\envs\\bluecast\\lib\\site-packages\\bluecast\\preprocessing\\encode_target_labels.py:65: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[6, 1, 0, 4, 6, ..., 3, 0, 3, 6, 3]\n",
      "Length: 16606\n",
      "Categories (7, int64): [0, 1, 2, 3, 4, 5, 6]' has dtype incompatible with category, please explicitly cast to a compatible dtype first.\n",
      "  targets.loc[:, col] = targets.loc[:, col].apply(lambda x: mapping.get(x, 999))\n",
      "d:\\anaconda3\\envs\\bluecast\\lib\\site-packages\\bluecast\\blueprints\\cast.py:247: UserWarning: Feature selection is disabled. Update the TrainingConfig param 'enable_feature_selection'\n",
      "            to enable it or make use of a custom preprocessor to do it manually during the last mile computations step.\n",
      "            Feature selection is recommended for datasets with many features (>1000). For datasets with a small amount\n",
      "            of features feature selection is not recommended.\n",
      "            \n",
      "  self.initial_checks(df)\n",
      "d:\\anaconda3\\envs\\bluecast\\lib\\site-packages\\bluecast\\blueprints\\cast.py:247: UserWarning: Cross validation is disabled. Update the TrainingConfig param 'hypertuning_cv_folds'\n",
      "            to enable it. Cross validation is disabled on default to allow fast prototyping. For robust hyperparameter\n",
      "            tuning using at least 5 folds is recommended.\n",
      "  self.initial_checks(df)\n",
      "d:\\anaconda3\\envs\\bluecast\\lib\\site-packages\\bluecast\\blueprints\\cast.py:247: UserWarning: Precise fine tuning has been enabled. Please make sure to transform your data to a normal\n",
      "            distribution (yeo-johnson). This is an experimental feature as it includes a special\n",
      "            evaluation (see more in the docs). If you plan to use this feature, please make sure to read the docs.\n",
      "  self.initial_checks(df)\n",
      "d:\\anaconda3\\envs\\bluecast\\lib\\site-packages\\bluecast\\blueprints\\cast.py:247: UserWarning: Precise fine tuning has been enabled, but number of hypertuning_cv_folds is less than 2. With\n",
      "            less than 2 folds precise_cv_tuning will not have any impact. Consider raising the number of folds to two\n",
      "            or higher or disable precise_cv_tuning.\n",
      "  self.initial_checks(df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid Input: 'cuda', valid values are: {'approx', 'auto', 'exact', 'gpu_hist', 'hist'}\n",
      "Xgboost uses CPU.\n",
      "2024-03-10 07:13:37.672025: Start detecting and casting feature types.\n",
      "2024-03-10 07:13:37.764045: Start fitting target label encoder.\n",
      "2024-03-10 07:13:37.771049: Start encoding target labels.\n",
      "2024-03-10 07:13:37.782050: Start executing train-test split with train size of 0.8.\n",
      "2024-03-10 07:13:37.820058: Start filling infinite values.\n",
      "2024-03-10 07:13:37.834022: Start filling infinite values.\n",
      "2024-03-10 07:13:37.837469: Start date column conversion.\n",
      "2024-03-10 07:13:37.859208: Start date column conversion.\n",
      "2024-03-10 07:13:37.871365: Start fitting DataFrame schema.\n",
      "2024-03-10 07:13:37.872285: Start checking if DataFrame schema of new data is consistent with previous data.\n",
      "2024-03-10 07:13:37.875697: Start checking if DataFrame schema of new data is consistent with previous data.\n",
      "2024-03-10 07:13:37.885698: Start fitting binary target encoder.\n",
      "2024-03-10 07:13:38.012534: Start transforming categories with binary target encoder.\n",
      "2024-03-10 07:13:38.032540: Start fitting multiclass target encoder.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\bluecast\\lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "d:\\anaconda3\\envs\\bluecast\\lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "d:\\anaconda3\\envs\\bluecast\\lib\\site-packages\\category_encoders\\ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "d:\\anaconda3\\envs\\bluecast\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [15:13:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "d:\\anaconda3\\envs\\bluecast\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [15:13:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\context.cc:44: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "d:\\anaconda3\\envs\\bluecast\\lib\\site-packages\\optuna\\samplers\\_tpe\\sampler.py:319: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-10 07:13:38.083552: Start transforming categories with multiclass target encoder.\n",
      "2024-03-10 07:13:38.096554: Start fitting Xgboost model.\n",
      "2024-03-10 07:13:38.096554: Start loading existing or default config files..\n",
      "2024-03-10 07:13:38.096554: Found provided TrainingConfig.\n",
      "2024-03-10 07:13:38.096554: Found provided XgboostTuneParamsConfig.\n",
      "2024-03-10 07:13:38.096554: Found provided XgboostFinalParamConfig.\n",
      "2024-03-10 07:13:38.127561: Start hyperparameter tuning of Xgboost model.\n",
      "2024-03-10 07:13:38.128565: Start checking if GPU is available for usage.\n",
      "Invalid Input: 'cuda', valid values are: {'approx', 'auto', 'exact', 'gpu_hist', 'hist'}\n",
      "Xgboost uses CPU.\n",
      "2024-03-10 07:13:38.134562: Start loading existing or default config files..\n",
      "2024-03-10 07:13:38.134562: Found provided TrainingConfig.\n",
      "2024-03-10 07:13:38.134562: Found provided XgboostTuneParamsConfig.\n",
      "2024-03-10 07:13:38.134562: Found provided XgboostFinalParamConfig.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: -0.890916: 100%|██████████| 500/500 [19:10<00:00,  2.30s/it, 1150.01/7200 seconds] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'objective': 'multi:softprob', 'booster': 'gbtree', 'eval_metric': 'mlogloss', 'tree_method': 'exact', 'num_class': 7, 'max_depth': 3, 'alpha': 1.799630072849584, 'lambda': 6.311168399434964, 'gamma': 1.0599636288857384, 'max_leaves': 0, 'subsample': 0.770721262749801, 'colsample_bytree': 0.5794484910138618, 'colsample_bylevel': 0.9923315418891239, 'eta': 0.14935042200972282, 'steps': 667}\n",
      "Finished hyperparameter tuning\n",
      "Start final model training\n",
      "\"['source'] not found in axis\"\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    automl.fit_eval(train.copy(), target_col=target)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "for model in automl.bluecast_models:\n",
    "    plot_tree(model.ml_model.model)\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(150, 80)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
